So we are estimateing Q(PC, a) value of each action.
The reward is mainly (B(newPC) - B(PC))
B(x) = # branches in that path

E: Short term

     - export our SAGE with OpenAI gym.
 - bring back RL strategies.  (23w oct !!!!)
 - TensorflowAgents,  => our script

A.
---------------------
River Conc:

 - simpletracer ? bcov ?
 - SAGE: python


	
  - Cpp, SAGE  
  - Evaluation with FuzzBench, Lava
  
  
-> replace simpletracer with emulation function code, make it common
  - genetic algorithms.



C. Tool usability:
-------------------
Check real problems catch <-- bring from River impl
Corpus folder
Dictionary
Smarter input
Distributed computing <-- Marius ?
Check other params from LibFuzzer: https://llvm.org/docs/LibFuzzer.html




